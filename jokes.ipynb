{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jokes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MSeobtZFkdEDl_KBekrUQyKtq18Ft6WW",
      "authorship_tag": "ABX9TyOyAnNLouinlo6sxtLztpRs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camen6ert/word_level_pytorch_lstm/blob/main/jokes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aect9hm9B90"
      },
      "source": [
        "#!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "#VERSION = \"nightly\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "#!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "#!python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz9YgIo3-80Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2431404-3909-411e-8588-fdd13793e7b4"
      },
      "source": [
        "# imports pytorch\n",
        "import torch\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "# imports the torch_xla package\n",
        "#import torch_xla\n",
        "#import torch_xla.core.xla_model as xm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSy6n--_CZyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa20a076-9db0-4097-a52d-40206f68dbff"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "train_on_gpu = False\n",
        "\n",
        "if device == 'cuda':\n",
        "  train_on_gpu = True\n",
        "\n",
        "print('Using {} device'.format(device))\n",
        "\n",
        "#device = xm.xla_device()\n",
        "#print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4_tHF6klmfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ade2e67b-dc79-4b67-e031-f1a6282c3a47"
      },
      "source": [
        "import re\n",
        "\n",
        "f = open(\"/content/drive/MyDrive/Colab Notebooks/data/witze2.txt\", \"r\")\n",
        "\n",
        "jokes = f.read()\n",
        "\n",
        "jokes = re.sub(r'[^\\w\\s\\n]','',jokes.lower())\n",
        "jokes = jokes.split(\"\\n\")\n",
        "print(jokes[:2])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['zwei bauern am stammtisch ich hab letzte woche alle meine tiere markieren müssen mit nem ring im linken ohr sauarbeit sag ich dir kann ich mir denken die ganzen kühe schweine schafe ja aber das schlimmste waren die bienen ', 'ein scharr nonnen kam zu petrus und wollt in den himmel petrus zur ersten nonne hast du schonmal einen penis angefasst die nonne ja aber nur mit der fingerspitze petrus dann tauche deine fingerspitze ins weihwasser und geh in den himmel petrus zur zweiten nonne hast du schonmal einen penis angefasst die nonne naja ich muss gestehen ich habe ihn massiert petrus dann tauche deine hand ins weihwasser und geh in den himmel plötzlich entsteht unruhe in der schlange weil sich eine der nonnen vorgedrängelt hat petrus fragt die nonne warum drängelst du dich vor die nonne na wenn ich das zeug schon gurgeln muss will ich es tun bevor schwester maria ihren arsch reinhält ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZevTPwVTcPZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b96075e-bb4c-4de4-c4f6-bf62c6cf70fc"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "words = [word.split(\" \") for word in jokes]\n",
        "all_words = [w for word in words for w in word]\n",
        "\n",
        "#word_buf = set()\n",
        "#for word in words:\n",
        "#  for w in word:\n",
        "#    word_buf.add(w)\n",
        "print(all_words[:10])\n",
        "word_counts = Counter(all_words)\n",
        "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "\n",
        "word2idx = {word: idx for (idx, word) in enumerate(vocab)}\n",
        "idx2word = {idx: word for (idx, word) in enumerate(vocab)}\n",
        "\n",
        "wordsNr = [word2idx[w] for word in words for w in word]\n",
        "\n",
        "print(word2idx['bauer'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['zwei', 'bauern', 'am', 'stammtisch', 'ich', 'hab', 'letzte', 'woche', 'alle', 'meine']\n",
            "299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwOsT-5XZTM1"
      },
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "sequence_len = 6\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvFmR0t8qIHo",
        "outputId": "53192c3b-9d17-4822-ad56-ac15040d597a"
      },
      "source": [
        "train_ds = []\n",
        "train_label_ds = []\n",
        "\n",
        "for i in range(len(wordsNr)//sequence_len):\n",
        "  k=0\n",
        "  train = wordsNr[i:i+sequence_len]\n",
        "  label = wordsNr[i+1:i+1+sequence_len]\n",
        "\n",
        "  #padding\n",
        "  if len(label) < sequence_len:\n",
        "    y = sequence_len - len(label)\n",
        "    for j in range(sequence_len - len(label)):\n",
        "      label.append(0)\n",
        "\n",
        "  train2 = [t for t in train]\n",
        "  label2 = [l for l in label]\n",
        "\n",
        "  train_ds.append(train2)\n",
        "  train_label_ds.append(label2)\n",
        "\n",
        "train_np = np.array(train_ds)\n",
        "train_label_np = np.array(train_label_ds)\n",
        "\n",
        "tensor_x = torch.LongTensor(train_np)\n",
        "tensor_y = torch.LongTensor(train_label_np)\n",
        "\n",
        "print(tensor_x.shape)\n",
        "print(tensor_y.shape)\n",
        "\n",
        "train_dataset = TensorDataset(tensor_x, tensor_y) # create your datset\n",
        "dataloader = DataLoader(train_dataset, batch_size=10, drop_last=True) # create your dataloader\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([71418, 6])\n",
            "torch.Size([71418, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhU-Kp6V0H4M"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, num_layers):\n",
        "        super(Model, self).__init__()\n",
        "        self.lstm_size = 256\n",
        "        self.embedding_dim = 256\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        n_vocab = len(idx2word)\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.lstm_size,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc = nn.Linear(self.lstm_size, len(vocab))\n",
        "\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        " \n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        #output, state = self.lstm2(embed, state)\n",
        "        output = self.fc(output)\n",
        "        return output, state\n",
        "\n",
        "    def init_hidden(self, bts):\n",
        "        return (torch.zeros(self.num_layers, bts, self.lstm_size).to(device),\n",
        "                torch.zeros(self.num_layers, bts, self.lstm_size).to(device))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnMbwvudkwwG"
      },
      "source": [
        "import argparse\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def train(dataset, model, batch_size, epoch, sequence_length):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i in range(epoch):\n",
        "      (h, c) = model.init_hidden(batch_size)\n",
        "      myLoss = 0\n",
        "      k = 0\n",
        "\n",
        "      for idx, (inputs, labels) in enumerate(dataset):\n",
        "\n",
        "        model.zero_grad()\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        output, (h, c) = model(inputs, (h, c))\n",
        "        \n",
        "        loss = criterion(output.transpose(1, 2), labels)\n",
        "\n",
        "        h = h.detach()\n",
        "        c = c.detach()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "\n",
        "        myLoss += loss.item()\n",
        "        k = idx\n",
        "\n",
        "        #if idx % 1000 == 999:\n",
        "        # print({ 'epoch': i, 'idx': idx, 'loss': loss.item() })          \n",
        "\n",
        "      print({ 'epoch': i, 'loss': myLoss/k })\n",
        "     # torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/data/joke_model')\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tPbiqYDsd3k"
      },
      "source": [
        "model = Model(5)\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/data/joke_model', map_location=torch.device(device)))\n",
        "\n",
        "model = model.to(device)\n",
        "print(device)\n",
        "\n",
        "train(dataloader, model, batch_size=10, epoch=30, sequence_length=sequence_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksigjPUSwt5c"
      },
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/data/joke_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlMyeo6qVWqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59964b3-54a4-420c-8cc6-b19b75634762"
      },
      "source": [
        "newModel = Model(5)\n",
        "\n",
        "newModel.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/data/joke_model', map_location=torch.device('cpu')))\n",
        "newModel.eval()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (embedding): Embedding(24563, 256)\n",
              "  (lstm): LSTM(256, 256, num_layers=5, batch_first=True)\n",
              "  (fc): Linear(in_features=256, out_features=24563, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXrl8DaTX5TS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc986f7-6683-4f98-ae9a-c8b98ce1c4dd"
      },
      "source": [
        "newModel.eval()\n",
        "\n",
        "\n",
        "text = \"sagt die nonne zum bauern\"\n",
        "words = text.split(' ')\n",
        "h = newModel.init_hidden(5)\n",
        "\n",
        "for i in range(0, 15):\n",
        "  arr = [word2idx[w] for w in words[i:]]\n",
        "  x = torch.tensor(arr)\n",
        "\n",
        "  x = x.unsqueeze(-1)\n",
        "  x = x.to(device)\n",
        "  y_pred, h = newModel(x, h)\n",
        "  last_word_logits = y_pred[0][-1]\n",
        "\n",
        "  p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "  word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "  words.append(idx2word[word_index])\n",
        "\n",
        "print(words)\n",
        "#word_index = np.random.choice(len(last_word_logits), p=p)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sagt', 'die', 'nonne', 'zum', 'bauern', 'ich', 'liebe', 'ja', 'notar', 'holger', 'muß', 'nebenan', 'dein', 'ja', 'jahre', 'wir', '', 'zimmer', 'schläft', 'petrus']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EtXovqHysIc"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}